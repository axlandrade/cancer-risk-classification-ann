{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bd9b8a",
   "metadata": {},
   "source": [
    "\n",
    "# Classificação de Risco de Câncer com Rede Neural Profunda (TensorFlow/Keras)\n",
    "\n",
    "Este notebook implementa um modelo de **Rede Neural Artificial profunda**, utilizando **TensorFlow/Keras**, para o problema de **classificação de risco de câncer**.\n",
    "\n",
    "Principais pontos:\n",
    "\n",
    "- Leitura do dataset a partir de **upload de arquivo CSV**.\n",
    "- **Limpeza e pré-processamento** dos dados (numéricos e categóricos).\n",
    "- Codificação das classes com `LabelEncoder`.\n",
    "- **Validação cruzada estratificada k-fold** (k = 10).\n",
    "- Treinamento de um novo modelo Keras em **cada fold**.\n",
    "- Cálculo da **acurácia média** e desvio padrão entre os folds.\n",
    "\n",
    "Requisito da disciplina: obter **acurácia média ≥ 0.70** na validação cruzada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5e600",
   "metadata": {},
   "source": [
    "## 1. Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b9eeb",
   "metadata": {},
   "source": [
    "## 2. Reprodutibilidade (semente aleatória)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44184e63",
   "metadata": {},
   "source": [
    "## 3. Upload do arquivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f935b",
   "metadata": {},
   "source": [
    "\n",
    "Faça o upload do arquivo **`classificacao_risco_cancer_varios_valores.csv`** no widget abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader = widgets.FileUpload(accept='.csv', multiple=False)\n",
    "display(uploader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea436589",
   "metadata": {},
   "source": [
    "### 3.1 Leitura do dataset enviado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6844ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(uploader.value) == 0:\n",
    "    raise ValueError(\"Nenhum arquivo enviado. Faça o upload do CSV no widget acima.\")\n",
    "\n",
    "# Extrair conteúdo do arquivo\n",
    "file_info = list(uploader.value.values())[0]\n",
    "file_content = file_info['content']\n",
    "\n",
    "# Ler CSV a partir de bytes\n",
    "df = pd.read_csv(io.BytesIO(file_content))\n",
    "\n",
    "print(\"Formato do dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac86150",
   "metadata": {},
   "source": [
    "## 4. Análise exploratória inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a64b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tipos de dados:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas numéricas\n",
    "df.describe(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas categóricas\n",
    "df.describe(include=['object'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfea1c0",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Limpeza dos dados e definição da variável alvo\n",
    "\n",
    "Passos adotados:\n",
    "\n",
    "1. Substituição de strings que representam valores ausentes (`\"NaN\"`, `\"nan\"`, `\"None\"`, `\"?\"`, etc.) por `NaN` real.\n",
    "2. Remoção da coluna de identificador (`Patient Id`), se existir.\n",
    "3. Definição de **`Level`** como variável-alvo.\n",
    "4. Remoção de linhas em que `Level` é ausente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15115a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df.copy()\n",
    "\n",
    "# Strings que representam valores nulos\n",
    "valores_nulos_str = [\"NaN\", \"nan\", \"NONE\", \"None\", \"?\", \"null\", \"NULL\", \" \"]\n",
    "dados = dados.replace(valores_nulos_str, np.nan)\n",
    "\n",
    "# Remover coluna de identificador, se presente\n",
    "if \"Patient Id\" in dados.columns:\n",
    "    dados = dados.drop(columns=[\"Patient Id\"])\n",
    "\n",
    "if \"Level\" not in dados.columns:\n",
    "    raise ValueError(\"A coluna 'Level' não foi encontrada no dataset. Verifique o nome da variável-alvo.\")\n",
    "\n",
    "# Remover linhas sem rótulo\n",
    "dados = dados.dropna(subset=[\"Level\"])\n",
    "\n",
    "X = dados.drop(columns=[\"Level\"])\n",
    "y = dados[\"Level\"]\n",
    "\n",
    "print(\"Formato de X:\", X.shape)\n",
    "print(\"Formato de y:\", y.shape)\n",
    "\n",
    "print(\"\\nDistribuição das classes em 'Level':\")\n",
    "print(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a635f",
   "metadata": {},
   "source": [
    "## 6. Separação de variáveis numéricas e categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_numericas = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "colunas_categoricas = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Variáveis numéricas:\", colunas_numericas)\n",
    "print(\"Variáveis categóricas:\", colunas_categoricas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2e688",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Pré-processamento dos atributos\n",
    "\n",
    "Será construído um **ColumnTransformer** para aplicar transformações distintas:\n",
    "\n",
    "- Atributos numéricos:\n",
    "  - `SimpleImputer(strategy=\"median\")`\n",
    "  - `StandardScaler()`\n",
    "\n",
    "- Atributos categóricos:\n",
    "  - `SimpleImputer(strategy=\"most_frequent\")`\n",
    "  - `OneHotEncoder(handle_unknown=\"ignore\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7904dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "transformador_numerico = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "transformador_categorico = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", transformador_numerico, colunas_numericas),\n",
    "        (\"cat\", transformador_categorico, colunas_categoricas)\n",
    "    ]\n",
    ")\n",
    "preprocessador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098449f0",
   "metadata": {},
   "source": [
    "## 8. Codificação da variável alvo (`LabelEncoder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Classes encontradas:\", list(label_encoder.classes_))\n",
    "print(\"Exemplo de codificação:\")\n",
    "for classe, codigo in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "    print(f\"{classe} -> {codigo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985181f",
   "metadata": {},
   "source": [
    "## 9. Definição do modelo Keras (rede neural profunda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Teste rápido da função (apenas para ver o resumo depois de conhecido o input_dim)\n",
    "print(\"Função de construção de modelo definida.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2c248",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Validação cruzada estratificada k-fold com Keras\n",
    "\n",
    "Configurações:\n",
    "\n",
    "- `k = 10` folds.\n",
    "- Para cada fold:\n",
    "  1. Ajusta-se o **pré-processador** apenas nos dados de treino do fold.\n",
    "  2. Transforma-se treino e validação.\n",
    "  3. Constrói-se um **novo modelo Keras**.\n",
    "  4. Treina-se o modelo no fold de treino.\n",
    "  5. Avalia-se a acurácia no fold de validação.\n",
    "- Ao final, calcula-se a **acurácia média** e o **desvio padrão**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded), start=1):\n",
    "    print(f\"\\n===== Fold {fold}/{k} =====\")\n",
    "    X_train_raw, X_val_raw = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    # Ajustar o pré-processador SOMENTE nos dados de treino\n",
    "    X_train_proc = preprocessador.fit_transform(X_train_raw)\n",
    "    X_val_proc = preprocessador.transform(X_val_raw)\n",
    "\n",
    "    input_dim = X_train_proc.shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    # Calcular pesos de classe para lidar com desbalanceamento (opcional, mas recomendado)\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights = {i: w for i, w in enumerate(class_weights_array)}\n",
    "\n",
    "    # Construir e treinar o modelo\n",
    "    model = build_model(input_dim, num_classes)\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Avaliação no fold\n",
    "    loss, acc = model.evaluate(X_val_proc, y_val, verbose=0)\n",
    "    print(f\"Acurácia no fold {fold}: {acc:.4f}\")\n",
    "    scores.append(acc)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"\\nAcurácias por fold (10-fold):\")\n",
    "print(scores)\n",
    "print(\"\\nAcurácia média: {:.4f}\".format(scores.mean()))\n",
    "print(\"Desvio padrão: {:.4f}\".format(scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228710d6",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Discussão dos resultados\n",
    "\n",
    "- A lista de acurácias por fold mostra o desempenho do modelo em cada uma das partições.\n",
    "- A **acurácia média** é a métrica principal de interesse.\n",
    "- O **desvio padrão** indica a estabilidade do modelo entre diferentes divisões do conjunto de dados.\n",
    "\n",
    "Se a acurácia média for **≥ 0.70**, o requisito do trabalho é atendido.  \n",
    "Caso contrário, é possível explorar:\n",
    "\n",
    "- Arquiteturas mais profundas (mais camadas ou mais neurônios).\n",
    "- Ajuste fino de hiperparâmetros (taxa de aprendizado, batch size, número de épocas).\n",
    "- Estratégias adicionais de balanceamento de classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c0a79",
   "metadata": {},
   "source": [
    "## 12. Experimentos adicionais (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d735a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espaço para testar novas arquiteturas, hiperparâmetros ou estratégias de pré-processamento.\n",
    "\n",
    "# Exemplo (rascunho):\n",
    "# def build_model_v2(input_dim, num_classes):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Input(shape=(input_dim,)),\n",
    "#         tf.keras.layers.Dense(256, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.4),\n",
    "#         tf.keras.layers.Dense(128, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.3),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "#         tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "#         loss='sparse_categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
